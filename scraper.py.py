# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13nbTtD1UPxJE2souD7Dx8vadv60J6AFX
"""

import os
import time
import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin
from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv()

def scrape_product_images(base_url, save_path, num_images=200):
    """
    Parses product images and names from an e-commerce catalog.

    Args:
        base_url (str): Base catalog URL without page number.
        save_path (str): Path to folder for saving images.
        num_images (int): Number of images to download.
    """

    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                      "AppleWebKit/537.36 (KHTML, like Gecko) "
                      "Chrome/120.0.0.0 Safari/537.36"
    }

    page = 1
    total_downloaded = 0

    while total_downloaded < num_images:
        url = f"{base_url}page/{page}/"
        print(f"Parsing page: {url}")

        try:
            response = requests.get(url, headers=headers)
            response.raise_for_status()

            soup = BeautifulSoup(response.content, 'html.parser')

            # Find all product blocks
            product_items = soup.find_all('li', class_='product') or \
                            soup.find_all('div', class_='product')

            if not product_items:
                print("No more products found. Exiting.")
                break

            for product_item in product_items:
                if total_downloaded >= num_images:
                    break

                # Extract image URL
                image_element = product_item.find('img', class_='attachment-woocommerce_thumbnail')
                image_url = None

                if image_element:
                    image_url = image_element.get('src')
                    srcset = image_element.get('srcset')
                    if srcset:
                        image_url = srcset.split(",")[-1].split()[0]

                if not image_url:
                    print("Skipped product: no image URL found.")
                    continue

                # Extract product name
                title_element = product_item.find('h2', class_='woocommerce-loop-product__title') or \
                                product_item.find('span', class_='woocommerce-loop-product__title') or \
                                product_item.find('a')

                product_name = title_element.text.strip() if title_element else f"product_{total_downloaded + 1}"

                try:
                    # Download image
                    image_response = requests.get(image_url, stream=True, headers=headers)
                    image_response.raise_for_status()

                    file_ext = image_url.split('.')[-1].split("?")[0]
                    if len(file_ext) > 5:
                        file_ext = "jpg"

                    image_name = f"{product_name.replace(' ', '_')}.{file_ext}"
                    file_path = os.path.join(save_path, image_name)

                    with open(file_path, 'wb') as file:
                        for chunk in image_response.iter_content(chunk_size=8192):
                            file.write(chunk)

                    total_downloaded += 1
                    print(f"Saved: {image_name} ({total_downloaded}/{num_images})")
                    time.sleep(1)

                except requests.exceptions.RequestException as e:
                    print(f"Failed to download image: {image_url} | Error: {e}")

            page += 1

        except requests.exceptions.RequestException as e:
            print(f"Request failed: {e}")
            break

# Entry point
if __name__ == "__main__":
    base_url = os.getenv("CATALOG_BASE_URL")
    save_path = "product_images"
    os.makedirs(save_path, exist_ok=True)

    scrape_product_images(base_url, save_path, num_images=200)